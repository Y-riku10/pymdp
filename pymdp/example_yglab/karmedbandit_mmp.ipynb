{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdp import utils\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "from pymdp.maths import softmax\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import jax.tree_util as jtu\n",
    "from jax import random as jr, config, jit\n",
    "from pymdp.jax.agent import Agent as AIFAgent\n",
    "from functools import partial\n",
    "from equinox import tree_at\n",
    "\n",
    "from pymdp.jax.maths import log_stable\n",
    "import jax\n",
    "e=0.0001#観測モデルの下駄（定常発火）\n",
    "sa1=0.5#観測モデルの標準偏差（支払い値をサンプリングするガウス分布の標準偏差）\n",
    "sa2=sa1\n",
    "sa3=sa1\n",
    "sa4=sa1\n",
    "sb1=0.28#状態遷移の標準偏差（減衰ランダムウォークの拡散ノイズの標準偏差）\n",
    "sb2=sb1\n",
    "sb3=sb1#4.28\n",
    "sb4=sb3#sb1\n",
    "ramda=0.98363#減衰ランダムウォークの減衰パラメータ\n",
    "#o_control=5#観測（支払い値）のデータ\n",
    "#u_control=1#選択された行動（スロット）\n",
    "cgrad=0.5#7.06#選好関数の傾き\n",
    "#cshape=2#選好関数の形状（対数の底）\n",
    "alpha=1.0#0.837#行動選択の精度\n",
    "num_obs = [11, 11, 11, 11] # observation modality dimensions，観測の次元数．観測は各スロットに対して，支払値なし，支払値1,支払値2，...支払値10の11通り．例）obs=[0,0,6,0]のとき，スロット3から支払値6が排出．\n",
    "num_states = [10, 10, 10, 10, 4] # hidden state factor dimensions，隠れ状態の次元数．1~4因子目：各スロットの平均支払値．5因子目：自分が選択したスロット．\n",
    "num_controls = [1, 1, 1, 1, 4] # control state factor dimensions，制御状態の次元数＝各隠れ状態に対するBの数．スロット1~4の平均支払値は行動に寄らず状態遷移確率が変わらないので制御状態の次元数1．行動によってどのスロットから支払値を獲得するかが変わる，スロットは4つなので制御状態は4つ\n",
    "\n",
    "Ns1=num_states[0]\n",
    "\n",
    "\n",
    "num_factors = len(num_states)\n",
    "D = utils.obj_array(num_factors)#初期事前分布の設定\n",
    "D[0] = np.ones(10)/10#スロット1の平均支払値が1~10の値を等確率で取りうるという事前信念\n",
    "D[1] = np.ones(10)/10\n",
    "D[2]= np.ones(10)/10\n",
    "D[3] = np.ones(10)/10\n",
    "#D[4] = np.zeros(8)\n",
    "D[4] = np.array([1/4, 1/4, 1/4 ,1/4])#自分が選んだスロット（行動）に対する信念．初期時刻はランダム．\n",
    "#D[4][u_control+3]=1\n",
    "\n",
    "                  \n",
    "#A_array = utils.random_A_matrix(num_obs, num_states) # create sensory likelihood (A matrix)\n",
    "A_shapes = [[o_dim] + num_states for o_dim in num_obs]\n",
    "# initialize the A array to all 0's\n",
    "A_array = utils.obj_array_zeros(A_shapes)\n",
    "l = np.arange(0,10,1)\n",
    "for m in range(0,num_states[0],1):\n",
    "    for n in range(0,num_states[1],1):\n",
    "        for o in range(0,num_states[2],1):\n",
    "            for p in range(0,num_states[3],1):\n",
    "                A_array[0][0,m,n,o,p,0]=0 #スロット1を選択したとき（制御状態0），スロット1の「支払値なし」の観測が生成される確率は0\n",
    "                A_array[0][1:11,m,n,o,p,0]=  norm.pdf(l,m,sa1)+e #平均m（因子1の隠れ状態）標準偏差sa1の正規分布にもとづく確率密度，10次元のベクトル．\n",
    "                A_array[0][0,m,n,o,p,1]=1#スロット1を選択したとき（制御状態0），スロット2の「支払値なし」の観測が生成される確率は1.\n",
    "                A_array[0][0,m,n,o,p,2]=1\n",
    "                A_array[0][0,m,n,o,p,3]=1\n",
    "\n",
    "\n",
    "for m in range(0,num_states[0],1):\n",
    "    for n in range(0,num_states[1],1):\n",
    "        for o in range(0,num_states[2],1):\n",
    "            for p in range(0,num_states[3],1):\n",
    "                \n",
    "                A_array[1][0,m,n,o,p,0]=1\n",
    "                A_array[1][0,m,n,o,p,1]=0\n",
    "                A_array[1][1:11,m,n,o,p,1]=norm.pdf(l,n,sa2)+e\n",
    "                A_array[1][0,m,n,o,p,2]=1\n",
    "                A_array[1][0,m,n,o,p,3]=1\n",
    "\n",
    "\n",
    "for m in range(0,num_states[0],1):\n",
    "    for n in range(0,num_states[1],1):\n",
    "        for o in range(0,num_states[2],1):\n",
    "            for p in range(0,num_states[3],1):\n",
    "                \n",
    "                A_array[2][0,m,n,o,p,0]=1\n",
    "                A_array[2][0,m,n,o,p,1]=1\n",
    "                A_array[2][0,m,n,o,p,2]=0\n",
    "                A_array[2][1:11,m,n,o,p,2]=norm.pdf(l,o,sa3)+e\n",
    "                A_array[2][0,m,n,o,p,3]=1\n",
    "\n",
    "\n",
    "for m in range(0,num_states[0],1):\n",
    "    for n in range(0,num_states[1],1):\n",
    "        for o in range(0,num_states[2],1):\n",
    "            for p in range(0,num_states[3],1):\n",
    "                \n",
    "                A_array[3][0,m,n,o,p,0]=1\n",
    "                A_array[3][0,m,n,o,p,1]=1\n",
    "                A_array[3][0,m,n,o,p,2]=1\n",
    "                A_array[3][0,m,n,o,p,3]=0\n",
    "                A_array[3][1:11,m,n,o,p,3]=norm.pdf(l,p,sa4)+e\n",
    "\n",
    "A_array = utils.norm_dist_obj_arr(A_array)#列ごとに正規化             \n",
    "\n",
    "B_shapes = [[s_dim, s_dim, num_controls[f]] for f, s_dim in enumerate(num_states)]\n",
    "# initialize the B array to uniform distributions as columns\n",
    "#uniform_B = utils.obj_array_uniform(B_shapes)\n",
    "#B_array = utils.random_B_matrix(num_states, num_controls) # create transition likelihood (B matrix)\n",
    "#rng = np.random.default_rng()#+rng.normal(0, sb1))\n",
    "# initialize the B array to all 0's\n",
    "B_array = utils.obj_array_zeros(B_shapes)\n",
    "theta=4 #減衰中心\n",
    "for st in range(0,num_states[0],1):\n",
    "    nexts=round(ramda*st+(1-ramda)*theta)#時刻tの平均支払値がstであるときの時刻t+1の平均支払値の期待値．\n",
    "    if nexts>9:\n",
    "        nexts=9\n",
    "    if nexts<0:\n",
    "        nexts=0\n",
    "    B_array[0][:,st,0]=norm.pdf(l,nexts,sb1)#平均がnexts，標準偏差がsb1の正規分布の確率密度．次の時点の隠れ状態に対する予測を記述．\n",
    "\n",
    "for st in range(0,num_states[1],1):\n",
    "    nexts=round(ramda*st+(1-ramda)*theta)\n",
    "    if nexts>9:\n",
    "        nexts=9\n",
    "    if nexts<0:\n",
    "        nexts=0\n",
    "    B_array[1][:,st,0]=norm.pdf(l,nexts,sb2)\n",
    "\n",
    "for st in range(0,num_states[2],1):\n",
    "    nexts=round(ramda*st+(1-ramda)*theta)\n",
    "    if nexts>9:\n",
    "        nexts=9\n",
    "    if nexts<0:\n",
    "        nexts=0\n",
    "    B_array[2][:,st,0]=norm.pdf(l,nexts,sb3)\n",
    "\n",
    "for st in range(0,num_states[3],1):\n",
    "    nexts=round(ramda*st+(1-ramda)*theta)\n",
    "    if nexts>9:\n",
    "        nexts=9\n",
    "    if nexts<0:\n",
    "        nexts=0\n",
    "    B_array[3][:,st,0]=norm.pdf(l,nexts,sb4)\n",
    "\n",
    "for controls in range(0,num_states[4],1):\n",
    "    B_array[4][controls,:,controls]=[1,1,1,1]#選択された制御状態に確率1で遷移する．\n",
    "B_array = utils.norm_dist_obj_arr(B_array)#列ごとに正規化  \n",
    "\n",
    "\n",
    "C_shapes = [[o_dim] for o_dim in num_obs]\n",
    "C_vector = utils.obj_array_zeros(C_shapes)\n",
    "C_vector[0][0]=0\n",
    "for m in range(1,num_obs[0],1):\n",
    "    C_vector[0][m] = cgrad* math.log(m)#スロット1の支払値に対する選好．対数関数で定義．\n",
    "C_vector[1][0]=0\n",
    "for m in range(1,num_obs[1],1):\n",
    "    C_vector[1][m] = cgrad* math.log(m)\n",
    "C_vector[2][0]=0\n",
    "for m in range(1,num_obs[2],1):\n",
    "    C_vector[2][m] = cgrad* math.log(m)\n",
    "C_vector[3][0]=0\n",
    "for m in range(1,num_obs[3],1):\n",
    "    C_vector[3][m] = cgrad* math.log(m)\n",
    "C_vector[0]=np.log(softmax(C_vector[0]))#softmaxで確率分布化⇒pymdpの仕様でlnp(o|C)の形式でAgentに入力する．\n",
    "C_vector[1]=np.log(softmax(C_vector[1]))\n",
    "C_vector[2]=np.log(softmax(C_vector[2]))\n",
    "C_vector[3]=np.log(softmax(C_vector[3]))\n",
    "\n",
    "#C_vector = utils.obj_array_uniform(num_obs) # uniform preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourArmedBandit(object):#生成プロセスの定義\n",
    "\n",
    "  def __init__(self, D_env):#初期化関数．各スロットの初期値をランダムに決定．\n",
    "\n",
    "    self.s_slot1 = utils.sample(D_env[0]) # randomly sample which bandit arm is better (Left or Right)\n",
    "    self.s_slot2 = utils.sample(D_env[1])\n",
    "    self.s_slot3 = utils.sample(D_env[2])\n",
    "    self.s_slot4 = utils.sample(D_env[3])\n",
    "    self.s_action = utils.sample(D_env[4])\n",
    "\n",
    "  def step(self, action_idx):#観測の生成関数．#(self, action_idx, o_control):\n",
    "    obs_slot1=0 #0:no cue\n",
    "    obs_slot2=0\n",
    "    obs_slot3=0\n",
    "    obs_slot4=0\n",
    "    #controlledobs_slot1=0\n",
    "    #controlledobs_slot2=0\n",
    "    #controlledobs_slot3=0\n",
    "    #controlledobs_slot4=0\n",
    "    \n",
    "    rng = np.random.default_rng()\n",
    "    self.s_slot1=round(ramda*self.s_slot1+(1-ramda)*theta+rng.normal(0, sb1))#真の平均支払い値の遷移\n",
    "    if self.s_slot1>9:#平均支払い値を1~10に収める\n",
    "        self.s_slot1=9\n",
    "    if self.s_slot1<0:\n",
    "        self.s_slot1=0\n",
    "    self.s_slot2=round(ramda*self.s_slot2+(1-ramda)*theta+rng.normal(0, sb2))#真の平均支払い値の遷移\n",
    "    if self.s_slot2>9:#平均支払い値を1~10に収める\n",
    "        self.s_slot2=9\n",
    "    if self.s_slot2<0:\n",
    "        self.s_slot2=0\n",
    "    self.s_slot3=round(ramda*self.s_slot3+(1-ramda)*theta+rng.normal(0, sb3))#真の平均支払い値の遷移\n",
    "    if self.s_slot3>9:#平均支払い値を1~10に収める\n",
    "        self.s_slot3=9\n",
    "    if self.s_slot3<0:\n",
    "        self.s_slot3=0\n",
    "    self.s_slot4=round(ramda*self.s_slot4+(1-ramda)*theta+rng.normal(0, sb4))#真の平均支払い値の遷移\n",
    "    if self.s_slot4>9:#平均支払い値を1~10に収める\n",
    "        self.s_slot4=9\n",
    "    if self.s_slot4<0:\n",
    "        self.s_slot4=0\n",
    "    \n",
    "    if action_idx[0][4] == 0:#制御状態が0のとき（スロット1を選択したとき）:\n",
    "      \n",
    "      A_env=np.zeros((11))\n",
    "      A_env[0]=0\n",
    "      A_env[1:11]=norm.pdf(l,self.s_slot1,sa1)\n",
    "      A_env = A_env/np.sum(A_env)\n",
    "      obs_slot1 = utils.sample(A_env)\n",
    "    \n",
    "    elif action_idx[0][4] == 1:#1:\n",
    "      \n",
    "      A_env=np.zeros((11))\n",
    "      A_env[0]=0\n",
    "      A_env[1:11]=norm.pdf(l,self.s_slot2,sa2)\n",
    "      A_env = A_env/np.sum(A_env)\n",
    "      obs_slot2 = utils.sample(A_env)\n",
    "    \n",
    "    elif action_idx[0][4] == 2:#2:\n",
    "      \n",
    "      A_env=np.zeros((11))\n",
    "      A_env[0]=0\n",
    "      A_env[1:11]=norm.pdf(l,self.s_slot3,sa3)\n",
    "      A_env = A_env/np.sum(A_env)\n",
    "      obs_slot3 = utils.sample(A_env)\n",
    "    \n",
    "    elif action_idx[0][4] == 3:#3:\n",
    "      \n",
    "      A_env=np.zeros((11))\n",
    "      A_env[0]=0\n",
    "      A_env[1:11]=norm.pdf(l,self.s_slot4,sa4)\n",
    "      A_env = A_env/np.sum(A_env)\n",
    "      obs_slot4 = utils.sample(A_env)\n",
    "\n",
    "    #elif action_idx == 4:\n",
    "      \n",
    "      #obs_slot1 = o_control\n",
    "    \n",
    "    #elif action_idx == 5:\n",
    "      \n",
    "      #obs_slot2 = o_control\n",
    "    \n",
    "    #elif action_idx == 6:\n",
    "      \n",
    "      #obs_slot3 = o_control\n",
    "    #elif action_idx == 7:\n",
    "      \n",
    "      #obs_slot4 = o_control\n",
    "    obs = [obs_slot1, obs_slot2, obs_slot3, obs_slot4]\n",
    "    obs_jax = jtu.tree_map(lambda x: jnp.expand_dims(x, -1).astype(jnp.int32), obs)#jax用にbatch次元？を追加\n",
    "    #return [[obs],[self] ]\n",
    "    return obs_jax\n",
    "  \n",
    "  def reset(self):#時刻1の観測のサンプリング#(self ,o_control):\n",
    "    \n",
    "    obs_slot1=0 #0:no cue\n",
    "    obs_slot2=0\n",
    "    obs_slot3=0\n",
    "    obs_slot4=0\n",
    "    if self.s_action == 0:\n",
    "      \n",
    "      A_env=np.zeros((11))\n",
    "      A_env[0]=0\n",
    "      A_env[1:11]=norm.pdf(l,self.s_slot1,sa1)\n",
    "      A_env = A_env/np.sum(A_env)\n",
    "      obs_slot1 = utils.sample(A_env)\n",
    "    \n",
    "    elif self.s_action == 1:\n",
    "      \n",
    "      A_env=np.zeros((11))\n",
    "      A_env[0]=0\n",
    "      A_env[1:11]=norm.pdf(l,self.s_slot2,sa2)\n",
    "      A_env = A_env/np.sum(A_env)\n",
    "      obs_slot2 = utils.sample(A_env)\n",
    "    \n",
    "    elif self.s_action == 2:\n",
    "      \n",
    "      A_env=np.zeros((11))\n",
    "      A_env[0]=0\n",
    "      A_env[1:11]=norm.pdf(l,self.s_slot3,sa3)\n",
    "      A_env = A_env/np.sum(A_env)\n",
    "      obs_slot3 = utils.sample(A_env)\n",
    "    \n",
    "    elif self.s_action == 3:\n",
    "      \n",
    "      A_env=np.zeros((11))\n",
    "      A_env[0]=0\n",
    "      A_env[1:11]=norm.pdf(l,self.s_slot4,sa4)\n",
    "      A_env = A_env/np.sum(A_env)\n",
    "      obs_slot4 = utils.sample(A_env)\n",
    "\n",
    "    #elif self.s_action == 4:\n",
    "      \n",
    "      #obs_slot1 = o_control\n",
    "    \n",
    "    #elif self.s_action == 5:\n",
    "      \n",
    "      #obs_slot2 = o_control\n",
    "    \n",
    "    #elif self.s_action == 6:\n",
    "      \n",
    "      #obs_slot3 = o_control\n",
    "    #elif self.s_action == 7:\n",
    "    \n",
    "      #obs_slot4 = o_control\n",
    "    obs = [obs_slot1, obs_slot2, obs_slot3, obs_slot4]\n",
    "    #print(obs)\n",
    "    obs_jax = jtu.tree_map(lambda x: jnp.expand_dims(x, -1).astype(jnp.int32), obs)#jax用にbatch次元？を追加\n",
    "    actions_t = jnp.array([[0,0,0,0,self.s_action]])\n",
    "    #return [[obs],[self] ]\n",
    "    #print(obs_jax)\n",
    "    return obs_jax, actions_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def run_active_inference_loop(my_agent, my_env, T = 10):\n",
    "batch_size = 1 # number of agents\n",
    "\n",
    "#jax\n",
    "\n",
    "A_jax = jtu.tree_map(lambda x: jnp.broadcast_to(x, (batch_size,) + x.shape), list(A_array))#jax用にbatch次元を追加．\n",
    "B_jax = jtu.tree_map(lambda x: jnp.broadcast_to(x, (batch_size,) + x.shape), list(B_array))\n",
    "C_jax = jtu.tree_map(lambda x: jnp.broadcast_to(x, (batch_size,) + x.shape), list(C_vector))\n",
    "D_jax = jtu.tree_map(lambda x: jnp.broadcast_to(x, (batch_size,) + x.shape), list(D))\n",
    "\n",
    "batch_keys = jr.split(jr.PRNGKey(0), batch_size)\n",
    "#batch_keys = jr.split(batch_keys[0], batch_size)\n",
    "#batch_keys = jr.split(batch_keys[0], batch_size)  \n",
    "\n",
    "A_dependencies=None#[[0, 4], [1, 4], [2,  4], [3, 4]]\n",
    "B_dependencies=None\n",
    "#AIFエージェントの宣言\n",
    "agents = AIFAgent(A=A_jax, B=B_jax, C=C_jax, D=D_jax, E=None, pA=None, pB=None,  inference_algo=\"mmp\", learn_A=False, learn_B=False, learn_C=False, learn_D=False, learn_E=False, A_dependencies=A_dependencies, B_dependencies=B_dependencies, gamma=1., alpha=1., action_selection=\"stochastic\", policy_len=1, use_utility=True, use_states_info_gain=True, use_param_info_gain=False, use_inductive=False, onehot_obs=False, sampling_mode=\"full\",num_iter=8)\n",
    "#AIFの処理を行う関数．「@partial～」をコメントアウトするとupdate_agent内でもprint文で出力を確認可能．\n",
    "@partial(jit, static_argnames=['batch_size','num_history'])\n",
    "def update_agent(agents, outcomes, actions, infer_args, batch_keys, batch_size=1, num_history=1000):\n",
    "\n",
    "    #認識・vfeの計算\n",
    "    beliefs,err, vfe,kld2, bs, un = agents.infer_states_vfe(outcomes, infer_args[0], past_actions=actions, qs_hist=infer_args[1])\n",
    "    #kld = agents.calc_KLD_past_currentqs(empirical_prior, infer_args[1], beliefs)\n",
    "    #行動選択確率（q_pi）の計算，efeの計算\n",
    "    q_pi, neg_efe, pbs, pkld, pfe, oRisk, pbs_pA, pbs_pB = agents.infer_policies_efe(beliefs)##\n",
    "    Hqo=pfe-pkld#q(o|π)のEntropy\n",
    "    negefe_tmp=neg_efe[0]-pbs_pA[0]-pbs_pB[0]#novelty項を除いたEFE\n",
    "    #print(f'    efe at time {t}: {neg_efe[0]}')\n",
    "\n",
    "    #行動のサンプリング\n",
    "    #batch_keys = jr.split(jr.PRNGKey(0), batch_size)\n",
    "    #actions_t, policy_idx = agents.sample_action_policy_idx(q_pi, rng_key=batch_keys)#q_pi_0\n",
    "    batch_keys = jr.split(batch_keys[0], batch_size)#乱数のシャッフル\n",
    "    actions_t = agents.sample_action(q_pi, rng_key=batch_keys)\n",
    "    #print(policy_idx)\n",
    "    #past_beliefs=next_past_beliefs\n",
    "\n",
    "    #行動・観測履歴・信念（認識）の配列の更新\n",
    "    if actions is not None:\n",
    "        actions = jnp.concatenate([actions, jnp.expand_dims(actions_t, -2)], -2)##次の推論でsampleactionしたものが使われる？\n",
    "    else:\n",
    "        actions = jnp.expand_dims(actions_t, -2)\n",
    "    outcomes = jtu.tree_map( lambda x: x[:, -num_history:], outcomes)\n",
    "    #print(f'    outcomes at time {T}: {outcomes}')\n",
    "    beliefs = jtu.tree_map( lambda x: x[:, -num_history:], beliefs)\n",
    "    #print(f'    beliefs at time {T}: {beliefs}')\n",
    "    actions = jtu.tree_map( lambda x: x[:,-num_history:], actions)\n",
    "    #print(f'    actions at time {T}: {actions}')\n",
    "    ###\n",
    "\n",
    "    # Dの学習\n",
    "    #agents = tree_at(lambda x: x.D, agents, jtu.tree_map(lambda x: x[:, 0], beliefs)) \n",
    "\n",
    "    #次のタイムステップのための事前分布（=MMPでは上の処理で作成したbeliefs）の作成\n",
    "    infer_args = agents.update_empirical_prior(actions_t, beliefs)\n",
    "    #empirical_prior = beliefs\n",
    "    #print(f'    infer_args at time {T}: {infer_args}')\n",
    "\n",
    "\n",
    "    # Learning #\n",
    "    ##学習用の観測・認識セットの準備\n",
    "    beliefs_last = jtu.tree_map( lambda x: x[:, -1:], beliefs) # take the last belief\n",
    "    #print(f'    beliefs_last at time {T}: {beliefs_last}')\n",
    "    outcomes_last = jtu.tree_map( lambda x: x[:, -1:], outcomes) # take the last outcome\n",
    "    #print(f'    outcomes_last at time {T}: {outcomes_last}')\n",
    "    applied_actions_last = jtu.tree_map( lambda x: x[:,-2:-1], actions) # take the last applied action\n",
    "    #print(f'    applied_actions_last at time {T}: {applied_actions_last}')\n",
    "    beliefs_last_pair = jtu.tree_map( lambda x: x[:, -2:], beliefs) # take the last two beliefs\n",
    "    ####\n",
    "\n",
    "    ##A,Bの更新（学習）\n",
    "    ##agents = agents.infer_parameters(beliefs_last, outcomes_last, applied_actions_last, beliefs_B=beliefs_last_pair)\n",
    "\n",
    "    # How to put learning rate\n",
    "    # lr_pA = 1.0 + jnp.zeros(batch_size)\n",
    "    # lr_pB = 1.0 + jnp.zeros(batch_size)\n",
    "    # agents = agents.infer_parameters(beliefs_last, outcomes_last, applied_actions_last, beliefs_B=beliefs_last_pair, lr_pA=lr_pA, lr_pB=lr_pB)\n",
    "    # learning using moving window (you have to put window size as num_history.)\n",
    "    # lr_pA = 1.0/num_history + jnp.zeros(batch_size)\n",
    "    # lr_pB = 1.0/num_history + jnp.zeros(batch_size)\n",
    "    # applied_actions = jtu.tree_map( lambda x: x[:,:-1], actions)\n",
    "    # agents = agents.infer_parameters(beliefs, outcomes, applied_actions, beliefs_B=beliefs, lr_pA=lr_pA, lr_pB=lr_pB) \n",
    "    #agents = tree_at(lambda x: x.onehot_obs, agents, True)\n",
    "    #agents = tree_at(lambda x: x.onehot_obs, agents, False)\n",
    "\n",
    "    vfe =vfe[0][0]\n",
    "    vfe=[vfe[-1]]#現在時点の隠れ状態に対するVFEを出力\n",
    "    bs =bs[0][0]\n",
    "    bs=[bs[-1]]#現在時点の隠れ状態に対するVFEを出力\n",
    "    un =un[0][0]\n",
    "    un=[un[-1]]#現在時点の隠れ状態に対するVFEを出力\n",
    "    #kld=kld[0]#kld1のとき\n",
    "    ##kld=kld2[0][0]\n",
    "    #kld=[kld[-1]]\n",
    "    return agents, outcomes, actions, infer_args, batch_keys, neg_efe, vfe,  bs, un, pbs, pbs_pA, pbs_pB,  Hqo, pkld, pfe, oRisk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert to distribution\n",
      "[Array([[[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)]\n",
      "selected action [[0 0 0 0 2]]\n",
      "convert to distribution\n",
      "[Array([[[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]]], dtype=float32), Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)]\n",
      "selected action [[0 0 0 0 1]]\n",
      "convert to distribution\n",
      "[Array([[[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]]], dtype=float32), Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)]\n",
      "selected action [[0 0 0 0 3]]\n",
      "convert to distribution\n",
      "[Array([[[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)]\n",
      "selected action [[0 0 0 0 2]]\n",
      "convert to distribution\n",
      "[Array([[[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]]], dtype=float32), Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)]\n",
      "selected action [[0 0 0 0 0]]\n",
      "convert to distribution\n",
      "[Array([[[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)]\n",
      "selected action [[0 0 0 0 2]]\n",
      "convert to distribution\n",
      "[Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]]], dtype=float32), Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)]\n",
      "selected action [[0 0 0 0 1]]\n",
      "convert to distribution\n",
      "[Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]]], dtype=float32), Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)]\n",
      "selected action [[0 0 0 0 3]]\n",
      "convert to distribution\n",
      "[Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)]\n",
      "selected action [[0 0 0 0 2]]\n",
      "convert to distribution\n",
      "[Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]]], dtype=float32), Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "T=10\n",
    "EFE=[]\n",
    "VFE=[]\n",
    "PBS=[]\n",
    "PKLD=[]\n",
    "PFE=[]\n",
    "Risk=[]\n",
    "Ambiguity=[]\n",
    "Pragmaticvalue=[]\n",
    "KLD=[]\n",
    "BS=[]\n",
    "\n",
    "D_env=D\n",
    "my_env=FourArmedBandit(D_env)\n",
    "obs, first_action = my_env.reset()#初期時刻の観測と行動のサンプリング\n",
    "#print(obs)\n",
    "obs_record=[obs]\n",
    "#chosen_policies=[first_action]\n",
    "#print(first_action)\n",
    "#policies=np.array([np.array([[0,0,0,0,0]]), np.array([[0,0,0,0,1]]), np.array([[0,0,0,0,2]]), np.array([[0,0,0,0,3]])])#np.array([np.array([[0]]),t=2:np.array([np.array([[1]]),..)\n",
    "#print(policies)\n",
    "\n",
    "#agents = AIFAgent(A=A_jax, B=B_jax, C=C_jax, D=D_jax, E=None, pA=None, pB=None, learn_A=False, learn_B=False, learn_C=False, learn_D=False, learn_E=False, A_dependencies=None, B_dependencies=None, gamma=1., alpha=1., inference_algo=\"fpi\", action_selection=\"stochastic\", policy_len=1, use_utility=True, use_states_info_gain=True, use_param_info_gain=False, use_inductive=False, onehot_obs=False, sampling_mode=\"full\")\n",
    "beliefs=None\n",
    "#print(agents.A_dependencies)\n",
    "#print(agents.B_dependencies)\n",
    "#print(agents.policies)\n",
    "for t in range(T):\n",
    "  if t == 0:\n",
    "      \n",
    "      actions_t = None ##first_action#None # no action available at the first time step\n",
    "      #print(actions_t)\n",
    "      actions = None # no action available at the first time step\n",
    "      prob_pi = None\n",
    "      #prob_pi = jnp.expand_dims(jnp.array([[0,0,0,0,self.s_action]]), -2) D_jax[4]\n",
    "      infer_args = (agents.D, None,)#(qs_pi, qs_hist)\n",
    "      outcome_t  = None\n",
    "      outcomes = None\n",
    "      #empirical_prior =agents.D　#KLD計算用の事前分布．\n",
    "  else:\n",
    "      print(\"selected action\",actions_t)\n",
    "      #empirical_prior = agents.compute_expected_state(actions_t, empirical_prior)#KLD計算用の事前分布．事前分布をB*qsとする場合\n",
    "\n",
    "  batch_keys = jr.split(batch_keys[0], batch_size)\n",
    "  outcome_t  = jtu.tree_map(lambda x: jnp.expand_dims(x, -1), obs)\n",
    "  #print(f'    outcome_t at time {T}: {outcome_t}')\n",
    "  \n",
    "  if outcomes is None:\n",
    "      outcomes = outcome_t\n",
    "  else:\n",
    "      outcomes = jtu.tree_map(lambda prev_o, new_o: jnp.concatenate([prev_o, new_o], -1), outcomes, outcome_t) \n",
    "\n",
    "  num_history=5 #推論する時間幅．5であれば現在から過去5タイムステップ分の隠れ状態を推論．\n",
    "  agents, outcomes, actions, infer_args, batch_keys, neg_efe, vfe,  bs, un, pbs,  pbs_pA, pbs_pB,  Hqo, pkld, pfe, oRisk = update_agent(\n",
    "      agents, \n",
    "      outcomes, \n",
    "      actions, \n",
    "      infer_args, \n",
    "      batch_keys,\n",
    "      batch_size=batch_size,\n",
    "      num_history=num_history\n",
    "  )\n",
    " \n",
    "  \"\"\" if T < num_history:\n",
    "    qs_1 = infer_args[1][0][0, 0] # snapshot of s1 for D-learning \"\"\"\n",
    "  actions_t = actions[:,-1]\n",
    "  #print(actions_t)\n",
    "  #print(actions_t[0][4])\n",
    "  obs = my_env.step(actions_t)#次の時刻の観測をサンプリング\n",
    "  #prev_obs=[obs]#次の時刻の観測を指定．\n",
    "  obs_record.append(obs)\n",
    "  #chosen_policy_idx=int(actions_t[4])    \n",
    "\n",
    "  #情報量記録\n",
    "  \"\"\" efe = np.array(-neg_efe[0])\n",
    "  min_index = np.argmin(efe)  # efeの最小値のインデックスを取得\n",
    "  efe_min = efe[min_index] \"\"\"\n",
    "  #print(f'    efe_min at time {T}: {efe_min}')\n",
    "  #efes.append(efe_min)\n",
    "  PBS.append(pbs)#=np.append(PBS,pbs)  \n",
    "  PKLD.append(pkld)\n",
    "  PFE.append(pfe)\n",
    "  Risk.append(oRisk)  \n",
    "  ambi=pfe-pbs-pkld\n",
    "  Ambiguity.append(ambi)\n",
    "  Pv=-oRisk+Hqo\n",
    "  Pragmaticvalue.append(Pv)\n",
    "  #chosen_policies.append(chosen_policy_idx)\n",
    "  #VFE.append(vfe)\n",
    "  EFE.append(-1*neg_efe)\n",
    "\n",
    "\n",
    "#可視化のためのデータ整形\n",
    "PBS=jtu.tree_map(lambda x: jnp.reshape(x, (4,)), PBS) \n",
    "PBS=np.array(PBS) \n",
    "PBS=PBS.T\n",
    "PBS=PBS.tolist()\n",
    "PKLD=jtu.tree_map(lambda x: jnp.reshape(x, (4,)), PKLD) \n",
    "PKLD=np.array(PKLD) \n",
    "PKLD=PKLD.T\n",
    "PKLD=PKLD.tolist()\n",
    "PFE=jtu.tree_map(lambda x: jnp.reshape(x, (4,)), PFE) \n",
    "PFE=np.array(PFE) \n",
    "PFE=PFE.T\n",
    "PFE=PFE.tolist()\n",
    "Ambiguity=jtu.tree_map(lambda x: jnp.reshape(x, (4,)), Ambiguity) \n",
    "Ambiguity=np.array(Ambiguity) \n",
    "Ambiguity=Ambiguity.T\n",
    "Ambiguity=Ambiguity.tolist()\n",
    "Risk=jtu.tree_map(lambda x: jnp.reshape(x, (4,)), Risk) \n",
    "Risk=np.array(Risk) \n",
    "Risk=Risk.T\n",
    "Risk=Risk.tolist()\n",
    "Pragmaticvalue=jtu.tree_map(lambda x: jnp.reshape(x, (4,)), Pragmaticvalue) \n",
    "Pragmaticvalue=np.array(Pragmaticvalue) \n",
    "Pragmaticvalue=Pragmaticvalue.T\n",
    "Pragmaticvalue=Pragmaticvalue.tolist()\n",
    "\n",
    "EFE=jtu.tree_map(lambda x: jnp.reshape(x, (4,)), EFE) \n",
    "EFE=np.array(EFE)\n",
    "EFE=EFE.T\n",
    "EFE=EFE.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Array([2], dtype=int32), Array([0], dtype=int32), Array([0], dtype=int32), Array([0], dtype=int32)], [Array([0], dtype=int32), Array([0], dtype=int32), Array([9], dtype=int32), Array([0], dtype=int32)], [Array([0], dtype=int32), Array([9], dtype=int32), Array([0], dtype=int32), Array([0], dtype=int32)], [Array([0], dtype=int32), Array([0], dtype=int32), Array([0], dtype=int32), Array([2], dtype=int32)], [Array([0], dtype=int32), Array([0], dtype=int32), Array([9], dtype=int32), Array([0], dtype=int32)], [Array([1], dtype=int32), Array([0], dtype=int32), Array([0], dtype=int32), Array([0], dtype=int32)], [Array([0], dtype=int32), Array([0], dtype=int32), Array([9], dtype=int32), Array([0], dtype=int32)], [Array([0], dtype=int32), Array([9], dtype=int32), Array([0], dtype=int32), Array([0], dtype=int32)], [Array([0], dtype=int32), Array([0], dtype=int32), Array([0], dtype=int32), Array([2], dtype=int32)], [Array([0], dtype=int32), Array([0], dtype=int32), Array([8], dtype=int32), Array([0], dtype=int32)], [Array([0], dtype=int32), Array([8], dtype=int32), Array([0], dtype=int32), Array([0], dtype=int32)]]\n"
     ]
    }
   ],
   "source": [
    "print(obs_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QStandardPaths: wrong permissions on runtime directory /run/user/1000/, 0755 instead of 0700\n"
     ]
    }
   ],
   "source": [
    "##プロット\n",
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')  # Qt5Aggをバックエンドとして使用\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "  labels=['1','2','3','4','5','6','7','8','9','10']  # set the dates as labels\n",
    "  x0 = np.arange(len(labels))  # create an array of values for the ticks that can perform arithmetic with width (w)\n",
    "\n",
    "# create the data groups with a dict comprehension and groupby\n",
    "  # マージンを設定\n",
    "  margin = 0.2  #0 <margin< 1\n",
    "  total_width = 1 - margin\n",
    "#EFEの可視化\n",
    "  fig, ax = plt.subplots()\n",
    "  # 棒グラフをプロット\n",
    "  \"\"\" for i, h in enumerate(EFE):\n",
    "    pos = x0 - total_width *( 1- (2*i+1)/len(EFE) )/2\n",
    "    plt.bar(pos, h, width = total_width/len(EFE)) \"\"\"\n",
    "  num_policies = 4\n",
    "  for i in range(num_policies):\n",
    "     pos = x0 - total_width *( 1- (2*i+1)/len(EFE) )/2\n",
    "     ax.bar(pos, EFE[i], width=total_width/len(EFE), label=f'Policy {i+1}')\n",
    "  # ラベルの設定\n",
    "  plt.xticks(x0, labels)\n",
    "  plt.xlabel(\"trial\", fontname=\"Arial\", fontsize=14)\n",
    "  plt.ylabel(\"EFE\", fontname=\"Arial\", fontsize=14)\n",
    "  ax.spines['top'].set_visible(False)\n",
    "  ax.spines['right'].set_visible(False)\n",
    "  plt.legend(fontsize=12, frameon=False)\n",
    "  plt.ylim(top=17.5) \n",
    "  plt.show\n",
    "# build the plots\n",
    "#subs = df.subsidiary.unique()\n",
    "  stacks = 4  # how many stacks in each group for a tick location\n",
    "# set the width\n",
    "  w = 0.15\n",
    "\n",
    "# this needs to be adjusted based on the number of stacks; each location needs to be split into the proper number of locations\n",
    "  x1 = [x0 - w*2, x0 - 2*w/3, x0 + 2*w/3, x0 + w*2]\n",
    "  data=[]\n",
    "  for p in range(0,agents.policies.ndim+1,1):\n",
    "\n",
    "    data.append(PBS[p])#ambiguity. (EFE=Ambiguity+Risk)\n",
    "    data.append(Pragmaticvalue[p])\n",
    "\n",
    "  data=np.array(data)#data.value.to_numpy() \n",
    "  #print(data)\n",
    "  fig, ax = plt.subplots()\n",
    "  colors = ['blue', 'orange' ]  # 各要素の色を指定\n",
    "  legends = ['Epistemic value','Pragmatic value']\n",
    "  for i, x in enumerate(x1):\n",
    "    if i==0:\n",
    "      ax.bar(x, PBS[i], width=w, color=colors[0],label=legends[0])\n",
    "      ax.bar(x, Pragmaticvalue[i], width=w, color=colors[1], label=legends[1])\n",
    "    else:\n",
    "      ax.bar(x, PBS[i], width=w, color=colors[0])\n",
    "      ax.bar(x, Pragmaticvalue[i], width=w, color=colors[1])\n",
    "  ax.axhline(0, color='black', linewidth=0.8)  # 0ラインを追加\n",
    "  ax.set_xticks(x0)\n",
    "  ax.set_xticklabels(labels)\n",
    "\n",
    "  plt.ylim(top=7.5) \n",
    "  plt.xticks(x0, labels)\n",
    "  plt.xlabel(\"trial\", fontname=\"Arial\", fontsize=14)\n",
    "  plt.ylabel(\"values\", fontname=\"Arial\", fontsize=14)\n",
    "  plt.legend(fontsize=12, loc=\"upper right\", frameon=False)\n",
    "  #plt.legend(legends, fontsize=12,loc=\"upper right\", frameon=False)\n",
    "  ax.spines['top'].set_visible(False)\n",
    "  ax.spines['right'].set_visible(False)\n",
    "  plt.show()\n",
    "  #Risk,Ambiguityの可視化，pBS,pKLDの可視化\n",
    "  \"\"\" data=[]\n",
    "  for p in range(0,agents.policies.ndim+1,1):\n",
    "\n",
    "    data.append(Ambiguity[p])#ambiguity. (EFE=Ambiguity+Risk)\n",
    "    data.append(Risk[p])\n",
    "\n",
    "  data=np.array(data)#data.value.to_numpy() \n",
    "  #print(data)\n",
    "  fig, ax = plt.subplots()\n",
    "  colors = ['green', 'black' ]  # 各要素の色を指定\n",
    "  legends = [ 'Ambiguity','Risk']\n",
    "  for x, j in zip(x1,list(range(4))):\n",
    "      bottom = 0\n",
    "      for i, color, legend in zip(list(range(2)), colors, legends):#Ambiguity,Risk\n",
    "          height = data[i+j*2] #.value.to_numpy()\n",
    "          ax.bar(x=x, height=height, width=w, bottom=bottom, color=color, label=legend)\n",
    "          bottom += height\n",
    "\n",
    "\n",
    "  ax.set_xticks(x0)\n",
    "  _ = ax.set_xticklabels(labels)\n",
    "  plt.xticks(x0, labels)\n",
    "  plt.xlabel(\"trial\", fontname=\"Arial\", fontsize=14)\n",
    "  plt.ylabel(\"EFE\", fontname=\"Arial\", fontsize=14)\n",
    "  plt.legend(legends, fontsize=12,loc=\"upper right\", frameon=False)\"\"\"\n",
    "  ##pBS,pKLDの可視化\n",
    "  \"\"\" data=[]\n",
    "  for p in range(0,agents.policies.ndim+1,1):\n",
    "    data.append(PKLD[p])#data.append(PKLD[p])\n",
    "    data.append(PBS[p])\n",
    "\n",
    "  data=np.array(data)#data.value.to_numpy() \n",
    "  #print(data) \n",
    "  fig, ax = plt.subplots()\n",
    "  colors = ['red','blue' ]  # 各要素の色を指定\n",
    "  legends = ['PKLD', 'PBS']\n",
    "  for x, j in zip(x1,list(range(4))):\n",
    "      bottom = 0\n",
    "      for i, color, legend in zip(list(range(2)), colors, legends):#PKLD,PBS,PFE,Risk\n",
    "          height = data[i+j*2] #.value.to_numpy()\n",
    "          ax.bar(x=x, height=height, width=w, bottom=bottom, color=color, label=legend)\n",
    "          bottom += height\n",
    "          \n",
    "  #ax.invert_yaxis()\n",
    "  ax.set_xticks(x0)\n",
    "  _ = ax.set_xticklabels(labels)\n",
    "  plt.xlabel(\"trial\", fontname=\"Arial\", fontsize=14)\n",
    "  plt.ylabel(\"predicted information gain\", fontname=\"Arial\", fontsize=14)\n",
    "  #plt.legend(fontsize=12, frameon=False)\n",
    "  # 指定した凡例のみを表示\n",
    "  ax.spines['top'].set_visible(False)\n",
    "  ax.spines['right'].set_visible(False)\n",
    "  plt.legend(legends, fontsize=12, loc=\"upper right\",frameon=False)\n",
    "  plt.show() \"\"\"\n",
    "\n",
    "  #print(outcomes)\n",
    "  #print(actions)\n",
    "  #print(prob_pi)\n",
    "  #print(beliefs)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
